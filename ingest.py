import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

# Charge la clÃ© depuis le .env
load_dotenv()

DATA_PATH = "./data"
CHROMA_PATH = "./chroma_db"

def ingest_documents():
    # 1. Check API Key
    if not os.getenv("OPENAI_API_KEY"):
        raise ValueError("ERREUR : Pas de clÃ© API trouvÃ©e. VÃ©rifie ton fichier .env !")

    # 2. SCAN
    print(f"ðŸ“‚ Scanning {DATA_PATH}...")
    if not os.path.exists(DATA_PATH):
        raise FileNotFoundError(f"Le dossier {DATA_PATH} n'existe pas.")
    
    loader = PyPDFDirectoryLoader(DATA_PATH)
    raw_documents = loader.load()
    print(f"ðŸ“„ {len(raw_documents)} pages chargÃ©es.")

    # 3. SPLIT
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        add_start_index=True,
    )
    chunks = text_splitter.split_documents(raw_documents)
    print(f"ðŸ§© {len(chunks)} fragments gÃ©nÃ©rÃ©s.")

    # 4. STORE (C'est lÃ  que Ã§a utilise tes crÃ©dits)
    print("ðŸ’¾ GÃ©nÃ©ration des embeddings via OpenAI...")
    db = Chroma.from_documents(
        documents=chunks, 
        embedding=OpenAIEmbeddings(),
        persist_directory=CHROMA_PATH
    )
    print(f"âœ… SUCCÃˆS : Base de donnÃ©es crÃ©Ã©e dans {CHROMA_PATH}.")

if __name__ == "__main__":
    ingest_documents()