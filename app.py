import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from graph import app as brain
from openai import OpenAI # On a besoin du client direct pour l'audio
from rag_tool import retrieve_context_documents
import streamlit as st
import os
# ... tes autres imports ...

# ðŸ‘‡ AJOUTE CE BLOC ICI ðŸ‘‡
# BOOTLOADER : VÃ©rification de la base de donnÃ©es au dÃ©marrage
CHROMA_PATH = "./chroma_db"

if not os.path.exists(CHROMA_PATH):
    # Si le dossier n'existe pas, on lance l'ingestion automatiquement
    with st.spinner("ðŸ§  Initialisation de la mÃ©moire (PremiÃ¨re exÃ©cution)..."):
        # On importe ton script d'ingestion comme un module
        import ingest
        # On force la crÃ©ation de la DB
        try:
            ingest.ingest_documents()
            st.success("âœ… MÃ©moire construite avec succÃ¨s !")
        except Exception as e:
            st.error(f"Erreur critique lors de l'ingestion : {e}")
            st.stop()
# ðŸ‘† FIN DU BLOC ðŸ‘†

# ... La suite de ton code (st.set_page_config, etc.) ...
st.set_page_config(page_title="One For All", page_icon="â™¾ï¸", layout="wide")

# --- SIDEBAR : CONFIGURATION UTILISATEUR ---
# --- SIDEBAR : CONFIGURATION & OUTILS ---
with st.sidebar:
    st.image("https://img.icons8.com/color/96/accessibility2.png", width=80)
    st.header("ðŸŽ›ï¸ Configuration")
    
    # 1. Choix du Handicap
    handicap_mode = st.radio(
        "Mode d'adaptation :",
        ["Standard", "FALC (Facile Ã  Lire)", "TDAH (Focus & Gras)", "DÃ©ficience Visuelle (Descriptif)"]
    )
    st.info(f"Mode activÃ© : **{handicap_mode}**")
    
    st.markdown("---")
    
    # 2. LE MICRO (DÃ‰PLACÃ‰ ICI) ðŸŽ™ï¸
    st.header("ðŸ—£ï¸ Mode Vocal")
    audio_value = st.audio_input("Cliquez pour enregistrer")
    if audio_value:
        st.caption("âœ… Audio capturÃ©. Traitement en cours...")

    st.markdown("---")
    st.caption("One For All - MVP v1.2")

# --- MEMOIRE ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Affichage historique
for message in st.session_state.messages:
    if isinstance(message, HumanMessage):
        with st.chat_message("user"):
            st.markdown(message.content)
    elif isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content)

# --- SAISIE ---
# --- SAISIE (MULTIMODAL : TEXTE + VOCAL) ---
# --- SAISIE PRINCIPALE ---
# Le micro est gÃ©rÃ© dans la sidebar, ici on gÃ¨re juste le texte
text_input = st.chat_input("Ã‰crivez votre question ici...")

# LOGIQUE DE PRIORITÃ‰ : AUDIO > TEXTE
final_user_input = None

if audio_value:
    # Si on a parlÃ© dans la sidebar, on traite l'audio
    # Pas besoin de spinner ici, Streamlit gÃ¨re le reload
    try:
        client = OpenAI()
        transcription = client.audio.transcriptions.create(
            model="whisper-1", 
            file=audio_value
        )
        final_user_input = transcription.text
    except Exception as e:
        st.sidebar.error(f"Erreur Micro : {e}")

elif text_input:
    # Sinon on prend le texte
    final_user_input = text_input
    
if final_user_input:
    # 1. On affiche et sauvegarde le message USER
    st.chat_message("user").markdown(final_user_input)
    st.session_state.messages.append(HumanMessage(content=final_user_input))

    # 2. LOGIQUE D'ADAPTATION (THE STYLIST)
    style_instruction = ""
    if handicap_mode == "FALC (Facile Ã  Lire)":
        style_instruction = "RÃ‰PONDS EN FALC (Facile Ã  Lire et Ã  Comprendre) : Phrases courtes. Mots simples. Pas de jargon."
    elif handicap_mode == "TDAH (Focus & Gras)":
        style_instruction = "ADAPTATION TDAH : Mets en **GRAS** les concepts clÃ©s. Structure aÃ©rÃ©e. Va droit au but."
    elif handicap_mode == "DÃ©ficience Visuelle (Descriptif)":
        style_instruction = "ADAPTATION VISUELLE : DÃ©cris ce qui est visuel. Sois trÃ¨s explicite."
    
    # 3. APPEL AU CERVEAU
    with st.spinner(f"Analyse & Adaptation ({handicap_mode})..."):
        # Injection du style
        system_prompt = SystemMessage(content=f"INSTRUCTION DE STYLE : {style_instruction}")
        input_messages = [system_prompt] + st.session_state.messages
        
        # Le Cerveau rÃ©flÃ©chit
        result = brain.invoke({"messages": input_messages})
        ai_response = result["messages"][-1]
        
        # RÃ©cupÃ©ration des sources (Hack MVP)
        from rag_tool import retrieve_context_documents
        sources = retrieve_context_documents(final_user_input)

    # 4. AFFICHAGE DE LA RÃ‰PONSE (Une seule fois !)
    st.chat_message("assistant").markdown(ai_response.content)
    
    # 5. AFFICHAGE DES SOURCES
    if sources:
        with st.expander("ðŸ“š Sources officielles utilisÃ©es"):
            for doc in sources:
                source_name = doc.metadata.get('source', 'Inconnu').split('/')[-1]
                page_num = doc.metadata.get('page', '?')
                st.caption(f"ðŸ“„ **{source_name}** (Page {page_num})")
                st.text(doc.page_content[:150] + "...")

    # 6. SAUVEGARDE EN MÃ‰MOIRE
    st.session_state.messages.append(ai_response)

    # 7. GÃ‰NÃ‰RATION AUDIO (TTS)
    client = OpenAI()
    try:
        response = client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input=ai_response.content[:4096] 
        )
        audio_file = "speech.mp3"
        response.stream_to_file(audio_file)
        st.audio(audio_file, format="audio/mp3", start_time=0)
    except Exception as e:
        st.warning(f"Audio non disponible : {e}")